 - Description

Social media bots have been around nowadays. They are designed to act like humans - automatically tweeting, retweeting, and responding to other's posts. In addition to bots, there has emerged cyborg referred to either bot-assisted human or human-assisted bot. They are usually maintained by some companies or websites as a media channel and customer service. Most of bots are designed to provide particular services, but they can be very harmful. They can mislead, exploit, and manipulate social media discourse with rumors, spam, malware, misinformation, slander, or even just noise.

 - What is the problem?
Twitter bots have become increasingly intelligent and complicated, making their detection more difficult. For example, social bots can search the Web for information and media to fill their profiles, and post collected material at predetermined times, emulating the human temporal signature of content production and consumption—including circadian patterns of daily activity and temporal spikes of information generation.They can even engage in more complex types of interactions, such as entertaining conversations with other people, commenting on their posts, and answering their questions. To acquire visibility, they can infiltrate popular discussions, generating topically-appropriat —and even potentially interesting— content, by identifying relevant keywords and searching online for information fitting that conversation. They can also automatically produce responses through natural language algorithms

 - What data do they collect?
 
Relationship graph of users.
Particular features of users, such as number of tweets, number of friends & followers, temporal features of tweets, tweeting devices used, etc.

 - What method do they use?

Examining the structure of a social graph. SybilRank for example assumes that sybil accounts exhibit a small number of links to legitimate users, instead connecting mostly to other sybils, as they need a large number of social ties to appear trustworthy. Some detection methods can be used to reveal such tightly-knit local communities. This kind of methods is not very powerful since attackers can mimic legitimate accounts community structure. As graph goes large, things can be much more complicated.

Crowd-sourcing bot detection. Given profiles of some users, it is observed that a group of workers can distinguish bots from legitimate users at a very high accuracy. This method is not cost-effect for a platform with a large pre-existing user base like Tweeter and Facebook. Also it involves some privacy issues.

Feature-based bot detection. Implements a detection algorithm relying upon several highly-predictive features which capture a variety of suspicious behaviors and separate social bots from humans.
